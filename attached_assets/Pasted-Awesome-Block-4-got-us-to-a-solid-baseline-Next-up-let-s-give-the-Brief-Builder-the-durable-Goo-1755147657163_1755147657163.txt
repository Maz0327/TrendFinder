Awesome—Block #4 got us to a solid baseline. Next up, let’s give the Brief Builder the durable, “Google-Slides-like” backbone it needs.

Below is a single, copy-paste Replit Task Block #5. It creates the Brief Canvas data model + APIs (blocks, assets, autosave), adds secure upload support, and wires smoke tests. It pauses where a human action is required.

⸻

🔧 REPLIT TASK BLOCK #5 — Brief Canvas Data Model, APIs & Uploads

Goal: Persist editable “blocks” on a brief (text/image/capture/etc.), support asset uploads (images/video stills), and expose clean /api/briefs/:id/blocks CRUD + /api/uploads/brief-asset for signed uploads. Keep everything compatible with our unified API.
Do not touch Supabase directly from the client; all calls go through the server.

0) Prep (branch + quick status)
	•	Open shell and run:

git checkout -b feature/brief-canvas-blocks
git status


⸻

1) 📦 DB migration (SQL) — tables, policies, triggers

HUMAN STOP A (Supabase SQL Editor): Paste and run the SQL below in your Supabase project (schema: public). This is idempotent and safe.

-- Function to maintain updated_at
create or replace function public.touch_updated_at()
returns trigger language plpgsql as $$
begin new.updated_at := now(); return new; end$$;

-- Brief blocks table (positioned elements on a canvas)
create table if not exists public.brief_blocks (
  id uuid primary key default gen_random_uuid(),
  brief_id uuid not null references public.dsd_briefs(id) on delete cascade,
  kind text not null check (kind in ('text','image','capture','quote','heading','list','shape')),
  content jsonb not null default '{}'::jsonb, -- block-specific payload (text, styles, refs)
  x numeric not null default 0,  -- left (% or px depending on client convention)
  y numeric not null default 0,  -- top
  w numeric not null default 400,
  h numeric not null default 200,
  z integer not null default 0,
  order_index integer not null default 0,
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now()
);

drop trigger if exists trg_brief_blocks_touch on public.brief_blocks;
create trigger trg_brief_blocks_touch
before update on public.brief_blocks
for each row execute function public.touch_updated_at();

create index if not exists brief_blocks_brief_id_idx on public.brief_blocks(brief_id);
create index if not exists brief_blocks_order_idx on public.brief_blocks(brief_id, order_index);

-- Optional: dedicated assets table (uploaded images/screens)
create table if not exists public.brief_assets (
  id uuid primary key default gen_random_uuid(),
  brief_id uuid not null references public.dsd_briefs(id) on delete cascade,
  kind text not null check (kind in ('image','video','graphic')),
  storage_path text not null,
  width integer,
  height integer,
  mime text,
  meta jsonb not null default '{}'::jsonb,
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now()
);

drop trigger if exists trg_brief_assets_touch on public.brief_assets;
create trigger trg_brief_assets_touch
before update on public.brief_assets
for each row execute function public.touch_updated_at();

create index if not exists brief_assets_brief_idx on public.brief_assets(brief_id);

-- RLS (assumes dsd_briefs.user_id exists and is FK to auth.users(id))
alter table public.brief_blocks enable row level security;
alter table public.brief_assets enable row level security;

-- Policies: owner can do all, using brief ownership
drop policy if exists brief_blocks_owner_all on public.brief_blocks;
create policy brief_blocks_owner_all on public.brief_blocks
using (exists (
  select 1 from public.dsd_briefs b
  where b.id = brief_id and b.user_id = auth.uid()
))
with check (exists (
  select 1 from public.dsd_briefs b
  where b.id = brief_id and b.user_id = auth.uid()
));

drop policy if exists brief_assets_owner_all on public.brief_assets;
create policy brief_assets_owner_all on public.brief_assets
using (exists (
  select 1 from public.dsd_briefs b
  where b.id = brief_id and b.user_id = auth.uid()
))
with check (exists (
  select 1 from public.dsd_briefs b
  where b.id = brief_id and b.user_id = auth.uid()
));

✅ When the SQL succeeds, return here and continue.

⸻

2) 🧠 Server: storage adapter extensions

Edit: server/storage.ts — add helpers for brief assets (re-use existing Supabase service client).

// server/storage.ts (append)
export interface BriefAssetRecord {
  id?: string;
  brief_id: string;
  kind: 'image' | 'video' | 'graphic';
  storage_path: string;
  width?: number;
  height?: number;
  mime?: string;
  meta?: any;
}

export async function recordBriefAsset(db: any, asset: BriefAssetRecord) {
  // db is supabase server-admin client already used elsewhere in this file
  const { data, error } = await db
    .from('brief_assets')
    .insert({
      brief_id: asset.brief_id,
      kind: asset.kind,
      storage_path: asset.storage_path,
      width: asset.width ?? null,
      height: asset.height ?? null,
      mime: asset.mime ?? null,
      meta: asset.meta ?? {}
    })
    .select()
    .single();
  if (error) throw error;
  return data;
}


⸻

3) 🛣️ Server routes: blocks CRUD + uploads

Add file: server/routes/brief-blocks.ts

import { Router } from 'express';
import { z } from 'zod';
import { requireAuth } from './middleware'; // existing auth middleware
import { getSupabaseForUser } from '../supabase'; // existing helper to get service client with RLS as user

const router = Router();
const BlockKind = z.enum(['text','image','capture','quote','heading','list','shape']);

const BlockCreate = z.object({
  kind: BlockKind,
  content: z.any().optional().default({}),
  x: z.number().nonnegative().default(0),
  y: z.number().nonnegative().default(0),
  w: z.number().positive().default(400),
  h: z.number().positive().default(200),
  z: z.number().int().default(0),
  order_index: z.number().int().default(0),
});

const BlockPatch = z.object({
  content: z.any().optional(),
  x: z.number().optional(),
  y: z.number().optional(),
  w: z.number().optional(),
  h: z.number().optional(),
  z: z.number().int().optional(),
  order_index: z.number().int().optional(),
});

router.use(requireAuth);

// List blocks for a brief
router.get('/api/briefs/:id/blocks', async (req, res) => {
  const user = req.user!;
  const briefId = req.params.id;
  const db = getSupabaseForUser(user);
  const { data, error } = await db
    .from('brief_blocks')
    .select('*')
    .eq('brief_id', briefId)
    .order('order_index', { ascending: true });
  if (error) return res.status(400).json({ error: error.message });
  res.json({ data });
});

// Create a block
router.post('/api/briefs/:id/blocks', async (req, res) => {
  const user = req.user!;
  const briefId = req.params.id;
  const body = BlockCreate.parse(req.body || {});
  const db = getSupabaseForUser(user);

  const { data, error } = await db
    .from('brief_blocks')
    .insert({ brief_id: briefId, ...body })
    .select()
    .single();

  if (error) return res.status(400).json({ error: error.message });
  res.json(data);
});

// Patch a block
router.patch('/api/briefs/:id/blocks/:blockId', async (req, res) => {
  const user = req.user!;
  const briefId = req.params.id;
  const blockId = req.params.blockId;
  const patch = BlockPatch.parse(req.body || {});
  const db = getSupabaseForUser(user);

  const { data, error } = await db
    .from('brief_blocks')
    .update(patch)
    .eq('id', blockId)
    .eq('brief_id', briefId)
    .select()
    .single();

  if (error) return res.status(400).json({ error: error.message });
  res.json(data);
});

// Delete a block
router.delete('/api/briefs/:id/blocks/:blockId', async (req, res) => {
  const user = req.user!;
  const briefId = req.params.id;
  const blockId = req.params.blockId;
  const db = getSupabaseForUser(user);

  const { error } = await db
    .from('brief_blocks')
    .delete()
    .eq('id', blockId)
    .eq('brief_id', briefId);

  if (error) return res.status(400).json({ error: error.message });
  res.status(204).send();
});

export default router;

Add file: server/routes/uploads.ts (signed uploads + record)

import { Router } from 'express';
import { z } from 'zod';
import { requireAuth } from './middleware';
import { getSupabaseForUser, getSupabaseAdmin } from '../supabase';
import { recordBriefAsset } from '../storage';

const router = Router();
router.use(requireAuth);

const UploadReq = z.object({
  brief_id: z.string().uuid(),
  kind: z.enum(['image','video','graphic']),
  filename: z.string().min(1),
  contentType: z.string().min(1)
});

// Use Supabase Storage with signed URL (client uploads directly to storage)
router.post('/api/uploads/brief-asset', async (req, res) => {
  const user = req.user!;
  const { brief_id, kind, filename, contentType } = UploadReq.parse(req.body || {});
  const storagePath = `briefs/${brief_id}/${Date.now()}-${filename}`;

  const admin = getSupabaseAdmin();
  const { data: signed, error: signErr } = await admin.storage
    .from('brief-assets')
    .createSignedUploadUrl(storagePath);

  if (signErr) return res.status(400).json({ error: signErr.message });

  // record will be finalized by client after successful upload OR here eagerly:
  await recordBriefAsset(admin, {
    brief_id,
    kind,
    storage_path: storagePath,
    mime: contentType
  });

  res.json({
    uploadUrl: signed.signedUrl,
    path: storagePath
  });
});

export default router;

Wire routes: edit server/routes.ts to mount:

// server/routes.ts (append)
import briefBlocks from './routes/brief-blocks';
import uploads from './routes/uploads';

export function mountRoutes(app: any) {
  // ...existing mounts
  app.use(briefBlocks);
  app.use(uploads);
}

Restart dev server after changes.

⸻

4) 🧪 Smoke tests for new endpoints

Edit/create: scripts/smoke.ts — append a quick check:

import fetch from 'node-fetch';

async function smoke() {
  const token = process.env.TEST_BEARER || ''; // put a real JWT to test authenticated calls
  const headers = token ? { Authorization: `Bearer ${token}`, 'Content-Type': 'application/json' } : { 'Content-Type': 'application/json' };

  // Replace with an existing brief id to test manually
  const BRIEF_ID = process.env.TEST_BRIEF_ID || '';

  if (!BRIEF_ID || !token) {
    console.log('Set TEST_BEARER and TEST_BRIEF_ID to run deep smoke.');
    return;
  }

  // List blocks
  let r = await fetch(`http://localhost:5000/api/briefs/${BRIEF_ID}/blocks`, { headers });
  console.log('GET blocks:', r.status);

  // Create a text block
  r = await fetch(`http://localhost:5000/api/briefs/${BRIEF_ID}/blocks`, {
    method: 'POST', headers, body: JSON.stringify({ kind: 'text', content: { text: 'Hello' }, x: 80, y: 120 })
  });
  console.log('POST block:', r.status);

  // Signed upload
  r = await fetch(`http://localhost:5000/api/uploads/brief-asset`, {
    method: 'POST', headers, body: JSON.stringify({ brief_id: BRIEF_ID, kind: 'image', filename: 'test.png', contentType: 'image/png' })
  });
  console.log('POST upload signed URL:', r.status);
}

smoke().catch(err => { console.error(err); process.exit(1); });

Run (optional, if you have a token/brief id):

TEST_BEARER="<your_supa_jwt>" TEST_BRIEF_ID="<an_existing_brief_uuid>" node scripts/smoke.ts


⸻

5) 🏁 Verification
	•	Build + typecheck:

npm run typecheck || npx tsc --noEmit
npm run build || true

	•	Start dev server and check logs for new routes binding.
	•	Quick manual test in the app (once UI calls are wired later by Bolt):
	•	Create/open a brief.
	•	Hit the blocks endpoints via Postman or the smoke script.
	•	Call /api/uploads/brief-asset to get a signed URL (you can test the PUT to that URL with the image bytes later).

⸻

6) ✅ Commit

git add -A
git commit -m "feat(briefs): add brief_blocks + brief_assets tables, CRUD API, signed upload route"
git push -u origin feature/brief-canvas-blocks

HUMAN STOP B: Open a PR (if needed) and merge to main when you’re happy.

⸻

What’s next after Block #5
	•	Block #6: Media analysis endpoints (Quick vs Deep), queue scaffolding, and safe JSON outputs (to support your A/V understanding features).
	•	Then: Bolt UI will call these new endpoints; we integrate and remove the legacy UI.

If you want, I’ll draft Block #6 right after you kick this off.