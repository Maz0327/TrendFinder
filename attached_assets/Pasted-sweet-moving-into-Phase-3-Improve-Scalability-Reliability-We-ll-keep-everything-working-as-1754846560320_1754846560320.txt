sweet — moving into **Phase 3: Improve Scalability & Reliability**. We’ll keep everything working as-is, and add an **async job system backed by your Supabase DB** (durable), plus a small polish on rate-limiting. Copy/paste exactly as below.

---

# Phase 3 – Part 1: Durable Jobs (Postgres via Supabase)

## 0) Create a `jobs` table (run in Supabase SQL editor)

**Open Supabase → SQL → New query** and **RUN EXACTLY**:

```sql
create table if not exists public.jobs (
  id uuid primary key default gen_random_uuid(),
  type text not null,             -- e.g. 'ai.analyze', 'truth.analyze'
  payload jsonb not null default '{}'::jsonb,
  status text not null default 'queued',  -- queued|running|done|failed
  result jsonb,
  error text,
  attempts int not null default 0,
  max_attempts int not null default 3,
  created_at timestamptz not null default now(),
  started_at timestamptz,
  finished_at timestamptz,
  user_id uuid                     -- optional attribution
);

create index if not exists idx_jobs_status_created on public.jobs (status, created_at);
```

> If `gen_random_uuid()` isn’t enabled, run `create extension if not exists "pgcrypto";` once, then re-run the table SQL.

---

## 1) Add a tiny DB job queue

**Create file:** `server/jobs/dbQueue.ts`
**PASTE EXACTLY:**

```ts
import { storage } from "../storage";

export type JobStatus = "queued" | "running" | "done" | "failed";

export interface JobRecord {
  id: string;
  type: string;
  payload: any;
  status: JobStatus;
  result?: any;
  error?: string;
  attempts: number;
  max_attempts: number;
  created_at: string;
  started_at?: string;
  finished_at?: string;
  user_id?: string;
}

export const dbQueue = {
  async enqueue(type: string, payload: any, userId?: string): Promise<JobRecord> {
    const job = await storage.createJob({ type, payload, userId });
    return job;
  },

  async get(id: string): Promise<JobRecord | null> {
    return storage.getJobById(id);
  },

  async takeNext(): Promise<JobRecord | null> {
    // Advisory-lock style, but simplest approach: atomically mark one queued row as running
    return storage.takeNextQueuedJob();
  },

  async succeed(id: string, result: any) {
    await storage.completeJob(id, result);
  },

  async fail(id: string, error: string) {
    await storage.failJob(id, error);
  },

  async retryLater(id: string, error: string) {
    await storage.retryJob(id, error);
  },
};
```

---

## 2) Add storage helpers for jobs

**Open:** `server/storage.ts`
**ADD these methods EXACTLY to the exported storage object implementation (keep existing code; just append methods and necessary imports):**

1. **At the imports section add (if not present):**

```ts
import { v4 as uuid } from "uuid";
```

2. **Append these functions inside your storage implementation file (use your existing DB client inside storage):**

```ts
type NewJobInput = { type: string; payload: any; userId?: string };

async function createJob(input: NewJobInput) {
  const { type, payload, userId } = input;
  const id = uuid();
  const { data, error } = await this.client
    .from("jobs")
    .insert({
      id,
      type,
      payload,
      status: "queued",
      user_id: userId || null,
    })
    .select("*")
    .single();
  if (error) throw error;
  return data;
}

async function getJobById(id: string) {
  const { data, error } = await this.client.from("jobs").select("*").eq("id", id).single();
  if (error) return null;
  return data;
}

/**
 * Atomically take the oldest queued job and mark running.
 * NOTE: Supabase's JS client doesn't expose row-level locks; we emulate atomics with RPC-like update.
 */
async function takeNextQueuedJob() {
  // 1) Find the oldest queued job
  const { data: candidates, error: findErr } = await this.client
    .from("jobs")
    .select("*")
    .eq("status", "queued")
    .order("created_at", { ascending: true })
    .limit(1);
  if (findErr) throw findErr;
  const job = candidates?.[0];
  if (!job) return null;

  // 2) Try to update to running if still queued
  const { data: updated, error: updErr } = await this.client
    .from("jobs")
    .update({ status: "running", started_at: new Date().toISOString(), attempts: (job.attempts ?? 0) + 1 })
    .eq("id", job.id)
    .eq("status", "queued")
    .select("*")
    .single();

  if (updErr) {
    // Someone else took it, or conflict – just return null and worker loop will try again
    return null;
  }
  return updated;
}

async function completeJob(id: string, result: any) {
  const { error } = await this.client
    .from("jobs")
    .update({ status: "done", finished_at: new Date().toISOString(), result })
    .eq("id", id);
  if (error) throw error;
}

async function failJob(id: string, errMsg: string) {
  const { error } = await this.client
    .from("jobs")
    .update({ status: "failed", finished_at: new Date().toISOString(), error: errMsg })
    .eq("id", id);
  if (error) throw error;
}

async function retryJob(id: string, errMsg: string) {
  // Move back to queued if attempts < max_attempts
  const { data: job, error: getErr } = await this.client.from("jobs").select("*").eq("id", id).single();
  if (getErr || !job) throw getErr || new Error("Job not found");
  if ((job.attempts ?? 0) >= (job.max_attempts ?? 3)) {
    return failJob.call(this, id, errMsg || "max attempts reached");
  }
  const { error } = await this.client
    .from("jobs")
    .update({ status: "queued", error: errMsg || null })
    .eq("id", id);
  if (error) throw error;
}

// expose in storage
export const storage = {
  // ...existing methods
  createJob,
  getJobById,
  takeNextQueuedJob,
  completeJob,
  failJob,
  retryJob,
};
```

> If your `storage` object is structured differently, paste these methods into the appropriate place and export them. If you’re unsure, paste your `storage.ts` and I’ll fit it exactly.

---

## 3) Add a jobs worker

**Create file:** `server/jobs/worker.ts`
**PASTE EXACTLY:**

```ts
import { dbQueue } from "./dbQueue";
import { AIAnalyzer } from "../services/aiAnalyzer";
import { TruthAnalysisFramework } from "../services/truthAnalysisFramework";
import { logger } from "../logger";

const ai = new AIAnalyzer();
const truth = new TruthAnalysisFramework();

export function startDbWorker() {
  const intervalMs = Number(process.env.JOB_WORKER_INTERVAL_MS || 1500);
  let running = false;

  async function tick() {
    if (running) return;
    running = true;
    try {
      const job = await dbQueue.takeNext();
      if (!job) return; // nothing to do

      logger.info({ jobId: job.id, type: job.type }, "Worker picked job");

      try {
        let result: any = null;

        if (job.type === "ai.analyze") {
          const { title, content, platform = "web" } = job.payload || {};
          result = await ai.analyzeContent(title || "Analysis", content || "", platform);
          await dbQueue.succeed(job.id, result);
        } else if (job.type === "truth.analyze") {
          const { content, platform = "web", metadata = {} } = job.payload || {};
          result = await truth.analyzeContent(content || "", platform, metadata);
          await dbQueue.succeed(job.id, result);
        } else {
          await dbQueue.fail(job.id, `Unknown job type: ${job.type}`);
        }
      } catch (err: any) {
        logger.error({ jobId: job.id, err: err?.message }, "Job failed");
        // retry if possible
        await dbQueue.retryLater(job.id, err?.message || "Error");
      }
    } catch (e) {
      logger.error({ err: (e as Error).message }, "Worker loop error");
    } finally {
      running = false;
    }
  }

  // simple polling loop
  setInterval(tick, intervalMs);
  logger.info({ intervalMs }, "DB worker started");
}
```

---

## 4) Expose enqueue + status endpoints (new router)

**Create file:** `server/routes/jobs.ts`
**PASTE EXACTLY:**

```ts
import { Router, Response } from "express";
import { requireAuth, AuthedRequest } from "../middleware/auth";
import { z } from "zod";
import { validateBody, ValidatedRequest } from "../middleware/validate";
import { dbQueue } from "../jobs/dbQueue";
import { problem } from "../utils/problem";

export const jobsRouter = Router();

const aiEnqueueSchema = z.object({
  title: z.string().optional(),
  content: z.string().min(1),
  platform: z.string().optional().default("web"),
});

jobsRouter.post(
  "/jobs/enqueue/ai-analyze",
  requireAuth,
  validateBody(aiEnqueueSchema),
  async (req: ValidatedRequest<z.infer<typeof aiEnqueueSchema>> & AuthedRequest, res: Response) => {
    try {
      const { title, content, platform } = req.validated!.body!;
      const job = await dbQueue.enqueue("ai.analyze", { title, content, platform }, req.user!.id);
      res.status(202).json({ jobId: job.id, status: job.status });
    } catch (error) {
      return problem(res, 500, "Failed to enqueue job", (error as Error).message);
    }
  }
);

const truthEnqueueSchema = z.object({
  content: z.string().min(1),
  platform: z.string().optional().default("web"),
  metadata: z.record(z.any()).optional().default({}),
});

jobsRouter.post(
  "/jobs/enqueue/truth-analyze",
  requireAuth,
  validateBody(truthEnqueueSchema),
  async (req: ValidatedRequest<z.infer<typeof truthEnqueueSchema>> & AuthedRequest, res: Response) => {
    try {
      const { content, platform, metadata } = req.validated!.body!;
      const job = await dbQueue.enqueue("truth.analyze", { content, platform, metadata }, req.user!.id);
      res.status(202).json({ jobId: job.id, status: job.status });
    } catch (error) {
      return problem(res, 500, "Failed to enqueue job", (error as Error).message);
    }
  }
);

// GET /api/jobs/:id
jobsRouter.get("/jobs/:id", requireAuth, async (req: AuthedRequest, res: Response) => {
  try {
    const job = await dbQueue.get(req.params.id);
    if (!job) return problem(res, 404, "Job not found");
    res.json({ id: job.id, status: job.status, result: job.result, error: job.error, attempts: job.attempts });
  } catch (error) {
    return problem(res, 500, "Failed to fetch job", (error as Error).message);
  }
});

export default jobsRouter;
```

---

## 5) Mount the jobs router and start the worker

**Open:** `server/routes.ts`

1. **Add imports near the top:**

```ts
import jobsRouter from "./routes/jobs";
import { startDbWorker } from "./jobs/worker";
```

2. **Inside `registerRoutes(app: Express)` (after other `app.use("/api", ...)` lines), ADD:**

```ts
app.use("/api", jobsRouter);
```

3. **At the end of `registerRoutes(app)` just before returning `httpServer`, ADD:**

```ts
// Start durable DB-backed worker
startDbWorker();
```

> This runs in the same process (simple + fine for Replit). If you later run a separate worker process, we can guard this with an env flag.

---

## 6) Keep old sync endpoints working (no breaking changes)

* We’re **not** removing your existing `/api/ai/analyze` route.
* The new async flow is **optional**: enqueue → poll status.

---

## 7) Typecheck + run

**Replit shell:**

```bash
npm run typecheck || npx tsc --noEmit
npm run dev
```

**Test (in browser or curl with a valid JWT):**

```bash
# enqueue AI analyze
curl -s -X POST http://localhost:5000/api/jobs/enqueue/ai-analyze \
 -H "Authorization: Bearer YOUR_TOKEN" \
 -H "Content-Type: application/json" \
 -d '{"title":"Quick","content":"Example content for async analysis","platform":"web"}'

# then poll:
curl -s http://localhost:5000/api/jobs/JOB_ID_HERE \
 -H "Authorization: Bearer YOUR_TOKEN"
```

You should see the job move from `queued` → `running` → `done`, with `result`.

---

# Phase 3 – Part 2: Rate-limiting polish (bucket by route)

> You already have rate limiting, but let’s add **separate buckets** for public vs heavy endpoints.

**Install (if not already):**

```bash
npm i express-rate-limit
```

**Create file:** `server/middleware/rateLimit.ts`
**PASTE EXACTLY:**

```ts
import rateLimit from "express-rate-limit";

export const publicLimiter = rateLimit({
  windowMs: 60 * 1000,
  max: 60,
  standardHeaders: true,
  legacyHeaders: false,
});

export const heavyLimiter = rateLimit({
  windowMs: 60 * 1000,
  max: 20, // stricter for AI/scraping
  standardHeaders: true,
  legacyHeaders: false,
});
```

**Wire in routers (example):**

* In `server/routes/ai.ts`, at top imports:

```ts
import { heavyLimiter } from "../middleware/rateLimit";
```

* Wrap routes:

```ts
aiRouter.post("/ai/analyze", heavyLimiter, requireAuth, validateBody(aiAnalyzeSchema), async (...) => { ... });
aiRouter.post("/ai/hook-generator", heavyLimiter, requireAuth, validateBody(hookGenSchema), async (...) => { ... });
```

* In `server/routes/brightData.ts`:

```ts
import { heavyLimiter } from "../middleware/rateLimit";
...
brightDataRouter.post("/bright-data/fetch", heavyLimiter, requireAuth, validateBody(...), async (...) => { ... });
brightDataRouter.post("/bright-data/live", heavyLimiter, requireAuth, validateBody(...), async (...) => { ... });
```

* In `server/routes/jobs.ts`:

```ts
import { heavyLimiter } from "../middleware/rateLimit";
...
jobsRouter.post("/jobs/enqueue/ai-analyze", heavyLimiter, requireAuth, validateBody(...), async (...) => { ... });
jobsRouter.post("/jobs/enqueue/truth-analyze", heavyLimiter, requireAuth, validateBody(...), async (...) => { ... });
```

Typecheck + run again:

```bash
npm run typecheck || npx tsc --noEmit
npm run dev
```

---

## Done with Phase 3 ✅

You now have:

* A **durable job queue** (persisted in Supabase)
* A **worker** that processes AI/truth jobs in the background
* **Async job endpoints** (enqueue + status)
* **Per-bucket rate limits** for heavy endpoints

Say **“Phase 3 complete”** when these work, and I’ll give you **Phase 4** (tests: unit + integration, plus a GitHub Action) in the same precise, copy-paste style.
