Awesome—since Block #5 landed the analysis pipeline and attached results to captures, the next clean step for Replit is to expose those results in your read APIs so the UI (Bolt now, your main app later) can render insights without extra round-trips.

Here’s a single copy-paste runbook.

⸻

Replit Task Block #6 — Read-Model Enhancements for Captures (+ filters, caching)

Goal:
Enrich the captures list/detail APIs with the latest analysis summary, top labels, and simple filters. Add lightweight HTTP caching so lists are snappy. No UI work here—pure server/DB + tests.

0) Guardrails
	•	Don’t touch working auth, exports, or the analysis pipeline from Block #5.
	•	All reads remain under /api/*. No direct Supabase from client.
	•	Keep feature flags/env as they are.

⸻

1) DB: View for latest analysis per capture (idempotent)

Create migration server/migrations/20250814_capture_latest_analysis.sql:

-- Fast read-model exposing the most recent analysis per capture
create or replace view public.capture_latest_analysis as
select distinct on (ca.capture_id)
  ca.capture_id,
  ca.id as analysis_id,
  ca.provider,
  ca.mode,
  ca.status,
  ca.summary,
  ca.labels,
  ca.created_at as analyzed_at
from public.capture_analyses ca
order by ca.capture_id, ca.created_at desc;

-- Helpful index if not already present
create index if not exists idx_ca_by_capture_created
  on public.capture_analyses(capture_id, created_at desc);

HUMAN STOP (if needed): If migrations aren’t auto-applied, paste the SQL in Supabase SQL Editor and run. Then continue.

⸻

2) Server: extend captures endpoints

2.1 Add read-model join on list in your captures route handler (e.g., server/routes/captures.ts or wherever /api/captures list lives):
	•	Accept new query params:
	•	q (search in title/content/tags)
	•	label (filter captures whose latest analysis includes a label)
	•	analyzed = true|false (has/hasn’t latest analysis)
	•	projectId
	•	date_from, date_to (ISO)
	•	page, pageSize (defaults preserved)
	•	For each capture, left-join public.capture_latest_analysis by capture.id = capture_latest_analysis.capture_id.
	•	Shape the response items like:

{
  id, project_id, title, tags, created_at, updated_at,
  latest_analysis: {
    status, summary, labels, analyzed_at, provider, mode
  } | null
}


	•	Implement ETag/Last-Modified on the list:
	•	Compute lastModified as max(captures.updated_at, latest_analysis.analyzed_at) across the page.
	•	Respond with ETag (a stable hash of the page payload or (page,pageSize,filters,lastModified)), Last-Modified.
	•	If If-None-Match/If-Modified-Since matches, return 304 with empty body.

2.2 Detail endpoint /api/captures/:id:
	•	Embed latest_analysis in the same shape.
	•	(Optional) include analysis_count and has_deep_analysis (true if any analysis row for the capture has mode='deep').

Keep writes exactly as-is; this is read-only enrichment.

⸻

3) Labels filter implementation hints
	•	label filter should check latest labels JSON:

exists (
  select 1
  from jsonb_array_elements(cla.labels) l
  where lower(coalesce(l->>'name','')) = lower($1)
)


	•	If you store labels differently, adapt accordingly.

⸻

4) OpenAPI update

Update server/openapi.json for:
	•	GET /api/captures new query params + enriched item schema
	•	GET /api/captures/{id} enriched schema

Keep it brief—just enough for UI codegen/intellisense.

⸻

5) Smoke tests

Add scripts/smoke-captures-readmodel.ts:
	•	Create (or reuse) a capture that has at least one analysis row.
	•	Call GET /api/captures?page=1&pageSize=10.
	•	Assert items include latest_analysis for analyzed captures.
	•	Assert ETag is present; repeat with If-None-Match to get 304.
	•	Call with label=<oneKnownLabel> and confirm at least one item returns.
	•	Call GET /api/captures/:id and assert latest_analysis.summary is present or null.

Add script to package.json:

"scripts": {
  "smoke:captures:readmodel": "ts-node --transpile-only scripts/smoke-captures-readmodel.ts"
}


⸻

6) Verification — print this
	•	✅ View public.capture_latest_analysis exists
	•	✅ /api/captures returns latest_analysis{summary,labels,status,analyzed_at}
	•	✅ Filters: q, label, analyzed, projectId, date range
	•	✅ ETag/Last-Modified implemented; 304 honored
	•	✅ /api/captures/:id enriched detail
	•	✅ npm run smoke:captures:readmodel PASS

If anything fails, log: the failing endpoint + the exact error/body.

⸻

Why this next?
Your analysis pipeline is great, but until the read model is part of the list endpoints, the UI can’t feel “intelligent”. This block keeps the backend clean, performant (via view + indexes + 304s), and gives Bolt a stable, simple contract to render summaries, chips, and filters immediately. After this, we can move to (A) moments parity, (B) brief canvas AI-arrange endpoints, or (C) chrome extension ingestion tests—your call.